<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="gs2mesh: Surface Reconstruction from Gaussian Splatting via Novel Stereo Views.">
  <meta name="keywords" content="gs2mesh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Surface Reconstruction from Gaussian Splatting via Novel Stereo Views</title>
  <style>
    .title {
      font-size: 2rem;
    }
  </style>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" >
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="icon" href="./static/images/us_vs_sugar/cropped_hat_ours.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>  <!-- Import the component -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.4.0/model-viewer.min.js"></script>

  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet">
  <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
  <link rel="stylesheet" href="./static/css/dics.css">
  <script src="./static/js/dics.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', domReady);
    function domReady() {
        for (const e of document.querySelectorAll(".b-dics")) {
            new Dics({
                container: e,
                textPosition: "bottom"
            });
        }
    }
  </script>
  <style>
    .caption-container {
      text-align: center;
      margin: 10px 0;
      font-size: 1.2em;
      font-weight: bold;
    }
    @media (max-width: 600px) {
      .caption-container {
        font-size: 1em;
      }
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">Surface Reconstruction from Gaussian Splatting via Novel Stereo Views</h1>
            <h2 style="font-size:1.7rem">ECCV 2024</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Yaniv Wolf</a><sup>*</sup>,</span>
              <span class="author-block">
                Amit Bracha</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://ron.cs.technion.ac.il/">Ron Kimmel
              </span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <a href="https://cs.technion.ac.il/" class="author-block">Technion - Israel Institute of Technology, Haifa, Israel</a>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup> Indicates equal contribution</span>
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2404.01810.pdf"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2404.01810"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/yanivw12/gs2mesh/tree/main"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                <!-- Colab Link. -->
                <span class="link-block">
                  <a href="https://gs2mesh.github.io"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="Colab Logo" style="height: 1em; vertical-align: middle;">
                    </span>
                    <span>Colab Demo (coming soon)</span>
                  </a>
                </span>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="hero teaser">
  <div class="video-container" style="display: flex; justify-content: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/cjtmLDD8YZk?si=011_tHybkY491cpq" 
    title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; 
    gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
    </iframe>
  </div>
  <br>
  <div class="container is-max-desktop">
    <h2 class="hero-body">
      <p>
        <b>TL;DR:</b> We present a fast and accurate method to reconstruct smooth, geometrically-consistent surfaces from Gaussian Splatting models.
        Our method requires less than 5 minutes of additional computation time on top of the 3DGS scence capture, for a typical in-the-wild scene.
      </p>
    </h2>
  </div>


</section>

<section class="pipeline"></section>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/pipeline.jpeg" alt="Pipeline Image">
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, 3D Gaussian Splatting (3DGS) has emerged as an efficient approach for accurately representing scenes. However, despite its superior novel view synthesis capabilities, extracting the geometry of the scene directly from the Gaussian properties remains a challenge, as those are optimized based on a photometric loss. While some concurrent models have tried adding geometric constraints during the Gaussian optimization process, they still produce noisy, unrealistic surfaces.
            </p>
            <p>
            We propose a novel approach for bridging the gap between the noisy 3DGS representation and the smooth 3D mesh representation, by injecting real-world knowledge into the depth extraction process. Instead of extracting the geometry of the scene directly from the Gaussian properties, we instead extract the geometry through a pre-trained stereo-matching model. We render stereo-aligned pairs of images corresponding to the original training poses, feed the pairs into a stereo model to get a depth profile, and finally fuse all of the profiles together to get a single mesh.
            </p>
            <p>
            The resulting reconstruction is smoother, more accurate and shows more intricate details compared to other methods for surface reconstruction from Gaussian Splatting, while only requiring a small overhead on top of the fairly short 3DGS optimization process.
            </p>
            <p>
            We performed extensive testing of the proposed method on in-the-wild scenes, obtained using a smartphone, showcasing its superior reconstruction abilities. Additionally, we tested the method on the Tanks and Temples and DTU benchmarks, achieving state-of-the-art results.
            </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<p class="title is-3 mt-5 has-text-centered"> In-the-Wild Scenes from Uncontrolled Smartphone Videos</p>
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/us_vs_sugar/cropped_amit_image.jpeg" alt="Reference">
      <!-- <img src="./static/images/us_vs_sugar/cropped_amit_sugar.jpeg" alt="SuGaR"> -->
      <img src="./static/images/us_vs_sugar/cropped_amit_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/us_vs_sugar/cropped_hat_image.jpeg" alt="Reference">
      <!-- <img src="./static/images/us_vs_sugar/cropped_hat_sugar.jpeg" alt="SuGaR"> -->
      <img src="./static/images/us_vs_sugar/cropped_hat_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/us_vs_sugar/cropped_shoe_image.jpeg" alt="Reference">
      <!-- <img src="./static/images/us_vs_sugar/cropped_shoe_sugar.jpeg" alt="SuGaR"> -->
      <img src="./static/images/us_vs_sugar/cropped_shoe_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/us_vs_sugar/cropped_videogame_image.jpeg" alt="Reference">
      <!-- <img src="./static/images/us_vs_sugar/cropped_videogame_sugar.jpeg" alt="SuGaR"> -->
      <img src="./static/images/us_vs_sugar/cropped_videogame_ours.jpeg" alt="Ours">
    </div>
  </div>
</div>


<!-- <p class="title is-3 mt-5 has-text-centered"> Semi-Automatic Masking using SAM and Depth Projections</p> -->
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/masked/cropped_apples_image.jpeg" alt="Reference">
      <img src="./static/images/masked/cropped_apples_ours.jpeg" alt="Ours">
      <!-- <img src="./static/images/masked/cropped_apples_ours_masked.jpeg" alt="Ours Masked"> -->
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/masked/cropped_coffee_image.jpeg" alt="Reference">
      <img src="./static/images/masked/cropped_coffee_ours.jpeg" alt="Ours">
      <!-- <img src="./static/images/masked/cropped_coffee_ours_masked.jpeg" alt="Ours Masked"> -->
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/masked/cropped_sculpture_image.jpeg" alt="Reference">
      <img src="./static/images/masked/cropped_sculpture_ours.jpeg" alt="Ours">
      <!-- <img src="./static/images/masked/cropped_sculpture_ours_masked.jpeg" alt="Ours Masked"> -->
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/masked/cropped_dancer_image.jpeg" alt="Reference">
      <img src="./static/images/masked/cropped_dancer_ours.jpeg" alt="Ours">
      <!-- <img src="./static/images/masked/cropped_dancer_ours_masked.jpeg" alt="Ours Masked"> -->
    </div>
  </div>
</div>

<p class="title is-3 mt-5 has-text-centered"> DTU Dataset </p>
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 900px; height:900px;">
      <!-- <img src="./static/images/mobile_brick/cropped_aston_gt.jpeg" alt="Ground Truth"> -->
      <img src="./static/images/us_vs_2dgs/dtu97_2dgs.png" alt="2DGS">
      <img src="./static/images/us_vs_2dgs/dtu97_ours.png" alt="Ours">
    </div>
  </div>
</div>
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 900px; height:900px;">
      <!-- <img src="./static/images/mobile_brick/cropped_aston_gt.jpeg" alt="Ground Truth"> -->
      <img src="./static/images/us_vs_2dgs/dtu105_2dgs.png" alt="2DGS">
      <img src="./static/images/us_vs_2dgs/dtu105_ours.png" alt="Ours">
    </div>
  </div>
</div>
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 900px; height:900px;">
      <!-- <img src="./static/images/mobile_brick/cropped_aston_gt.jpeg" alt="Ground Truth"> -->
      <img src="./static/images/us_vs_2dgs/dtu110_2dgs.png" alt="2DGS">
      <img src="./static/images/us_vs_2dgs/dtu110_ours.png" alt="Ours">
    </div>
  </div>
</div>

<div class="caption-container" style="max-width: 800px; margin: 0 auto;">
  Quantitative results on the DTU Dataset. Chamfer distance - lower is better. Red-1<sup>st</sup>, Orange-2<sup>nd</sup>, Yellow-3<sup>rd</sup>. Table adapted from Gaussian Opacity Fields.
  Our method surpasses other Splatting-based methods, and is comparable with state-of-the-art neural methods such as Neuralangelo while taking significantly less time to run.
</div>

<iframe id="table-iframe" src="table.html?v=1" width="100%" style="border:none; display:block; height: 350px; overflow-y: hidden;"></iframe>

<p class="title is-3 mt-5 has-text-centered"> MobileBrick Dataset - Comparison with MVSFormer </p>
<div class="level">
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/mobile_brick/cropped_aston_gt.jpeg" alt="Ground Truth">
      <img src="./static/images/mobile_brick/cropped_aston_mvs.jpeg" alt="MVSFormer">
      <img src="./static/images/mobile_brick/cropped_aston_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/mobile_brick/cropped_big_ben_gt.jpeg" alt="Ground Truth">
      <img src="./static/images/mobile_brick/cropped_big_ben_mvs.jpeg" alt="MVSFormer">
      <img src="./static/images/mobile_brick/cropped_big_ben_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/mobile_brick/cropped_castle_gt.jpeg" alt="Ground Truth">
      <img src="./static/images/mobile_brick/cropped_castle_mvs.jpeg" alt="MVSFormer">
      <img src="./static/images/mobile_brick/cropped_castle_ours.jpeg" alt="Ours">
    </div>
  </div>
  <div class="level-item">
    <div class="b-dics" style="width: 300px; height:300px;">
      <img src="./static/images/mobile_brick/cropped_colosseum_gt.jpeg" alt="Ground Truth">
      <img src="./static/images/mobile_brick/cropped_colosseum_mvs.jpeg" alt="MVSFormer">
      <img src="./static/images/mobile_brick/cropped_colosseum_ours.jpeg" alt="Ours">
    </div>
  </div>
</div>

<div class="caption-container" style="max-width: 800px; margin: 0 auto;">
  Quantitative results on the MobileBrick Dataset. F1 - Higher is better, Chamfer distance - lower is better. Red-1<sup>st</sup>, Orange-2<sup>nd</sup>, Yellow-3<sup>rd</sup>.
</div>

<iframe id="table-iframe" src="table2.html?v=1" width="100%" style="border:none; display:block; height: 250px; overflow-y: hidden;"></iframe>

<!-- <p class="title is-4 mt-5 has-text-centered"> Tanks and Temples/In the Wild</p>
<div class="level">
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="dancer" src="./static/meshes/truck_simplified_025_compressed.glb" shadow-intensity="1" exposure="1.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 0" touch-action="pan-y"></model-viewer>
      <figcaption><strong>Tanks and Temples: Truck</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="flowers" src="./static/meshes/elephant_ours_simplified_025_compressed.glb" shadow-intensity="1" exposure="1.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 0" touch-action="pan-y"></model-viewer>
      <figcaption><strong>In the Wild: Elephant</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="elephant" src="./static/meshes/orchid_ours_simplified_025_compressed.glb" shadow-intensity="1" exposure="1.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 0" touch-action="pan-y"></model-viewer>
      <figcaption><strong>In the Wild: Orchid</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="dancer" src="./static/meshes/cactus_simplified_025_compressed.glb" shadow-intensity="1" exposure="1.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 0" touch-action="pan-y"></model-viewer>
      <figcaption><strong>In the Wild: Cactus</strong></figcaption>
    </figure>
  </div>
</div>

<p class="title is-4 mt-5 has-text-centered"> DTU</p>
<div class="level">
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="dancer" src="./static/meshes/DTU/dtu_24_compressed.glb" shadow-intensity="1" exposure="2.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 -90" touch-action="pan-y"></model-viewer>
      <figcaption><strong>DTU: Scan 24</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="flowers" src="./static/meshes/DTU/dtu_37_compressed.glb" shadow-intensity="1" exposure="2.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 -90" touch-action="pan-y"></model-viewer>
      <figcaption><strong>DTU: Scan 37</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="elephant" src="./static/meshes/DTU/dtu_105_compressed.glb" shadow-intensity="1" exposure="2.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 -90" touch-action="pan-y"></model-viewer>
      <figcaption><strong>DTU: Scan 105</strong></figcaption>
    </figure>
  </div>
  <div class="level-item">
    <figure style="width: 100%; text-align: center;">
      <model-viewer alt="dancer" src="./static/meshes/DTU/dtu_106_compressed.glb" shadow-intensity="1" exposure="2.0" style="width: 100%; height: 300px;" camera-controls auto-rotate orientation="0 180 -90" touch-action="pan-y"></model-viewer>
      <figcaption><strong>DTU: Scan 106</strong></figcaption>
    </figure>
  </div>
</div> -->

<!-- <p class="bottom-caption">Our method surpasses other Splatting-based methods, and is comparable with state-of-the-art neural methods such as Neuralangelo while taking significantly less time to run.</p> -->

<!-- <iframe src="table.html?v=1" width="100%" height="500px" style="border:none;"></iframe> -->


<section class="section" id="BibTeX</section>">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@article{wolf2024surface,
      title={Surface Reconstruction from Gaussian Splatting via Novel Stereo Views},
      author={Wolf, Yaniv and Bracha, Amit and Kimmel, Ron},
      journal={arXiv preprint arXiv:2404.01810},
      year={2024}
    }</code></pre>
  
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">References</h2>

        <div class="content has-text-justified">
          <p>
            Barron, Jonathan T., et al. "Mip-nerf 360: Unbounded anti-aliased neural radiance fields." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.
          </p>
          <p>
            Cao, Chenjie, Xinlin Ren, and Yanwei Fu. "MVSFormer: Multi-View stereo by learning robust image features and temperature-based depth." arXiv preprint arXiv:2208.02541 (2022).
          </p>
          <p>
            Gu√©don, Antoine, and Vincent Lepetit. "SuGaR: Surface-aligned Gaussian splatting for efficient 3D mesh reconstruction and high-quality mesh rendering." arXiv preprint arXiv:2311.12775 (2023).
          </p>
          <p>
            Huang, Binbin, et al. "2D Gaussian Splatting for Geometrically Accurate Radiance Fields." SIGGRAPH 2024 Conference Papers, Association for Computing Machinery, 2024, doi:10.1145/3641519.3657428.
          </p>
          <p>
            Jensen, Rasmus, et al. "Large Scale Multi-View Stereopsis Evaluation." 2014 IEEE Conference on Computer Vision and Pattern Recognition, IEEE, 2014, pp. 406-413.
          </p>
          <p>
            Kerbl, Bernhard, et al. "3D Gaussian splatting for real-time radiance field rendering." ACM Transactions on Graphics 42.4 (2023): 1-14.
          </p>
          <p>
            Kirillov, Alexander, et al. "Segment Anything." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.
          </p>
          <p>
            Knapitsch, Arno, et al. "Tanks and Temples: Benchmarking large-scale scene reconstruction." ACM Transactions on Graphics (ToG) 36.4 (2017): 1-13.
          </p>
          <p>
            Li, Kejie, et al. "MobileBrick: Building LEGO for 3D reconstruction on mobile devices." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.
          </p>
          <p>
            Li, Zhaoshuo, et al. "Neuralangelo: High-fidelity neural surface reconstruction." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.
          </p>
          <p>
            Mildenhall, Ben, et al. "Nerf: Representing scenes as neural radiance fields for view synthesis." Communications of the ACM 65.1 (2021): 99-106.
          </p>
          <p>
            Wang, Peng, et al. "Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction." arXiv preprint arXiv:2106.10689 (2021).
          </p>
          <p>
            Yariv, Lior, et al. "BakedSDF: Meshing neural SDFs for real-time view synthesis." ACM SIGGRAPH 2023 Conference Proceedings. 2023.
          </p>
          <p>
            Yariv, Lior, et al. "Volume rendering of neural implicit surfaces." Advances in Neural Information Processing Systems 34 (2021): 4805-4815.
          </p>
          <p>
            Yu, Zehao, Torsten Sattler, and Andreas Geiger. "Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in Unbounded Scenes." arXiv preprint arXiv:2404.10772 (2024).
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is based on <a href="https://github.com/nerfies/nerfies.github.io">this</a> source code, 
            <a href="https://github.com/abelcabezaroman/definitive-image-comparison-slider">this</a> code for the comparison slider
            and <a href="https://github.com/google/model-viewer?tab=readme-ov-file">this</a> code for the 3D model viewer. 
            3D models were compressed using <a href="https://gltf.report/">this</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
